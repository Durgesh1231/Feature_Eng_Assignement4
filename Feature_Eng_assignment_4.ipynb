{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9B_EK4Me9ix"
      },
      "outputs": [],
      "source": [
        "# Q1. Difference between Ordinal Encoding and Label Encoding:\n",
        "\n",
        "# Ordinal Encoding:\n",
        "# Ordinal encoding is used for categorical features that have an inherent order or ranking.\n",
        "# The categories are assigned integer values based on their rank.\n",
        "# Example: For the feature \"Education Level\" with values [\"High School\", \"Bachelor's\", \"Master's\", \"PhD\"],\n",
        "# ordinal encoding might assign values like:\n",
        "# \"High School\" -> 0, \"Bachelor's\" -> 1, \"Master's\" -> 2, \"PhD\" -> 3.\n",
        "\n",
        "# Label Encoding:\n",
        "# Label encoding assigns an integer to each category but does not take into account any inherent order.\n",
        "# It is suitable for nominal data, where the categories do not have a specific ranking.\n",
        "# Example: For the feature \"Color\" with values [\"Red\", \"Green\", \"Blue\"], label encoding might assign:\n",
        "# \"Red\" -> 0, \"Green\" -> 1, \"Blue\" -> 2.\n",
        "\n",
        "# When to choose one over the other:\n",
        "# - Use Ordinal Encoding when the categories have a meaningful order (e.g., \"Education Level\").\n",
        "# - Use Label Encoding when the categories are nominal and do not have a specific ranking (e.g., \"Color\").\n",
        "\n",
        "# Q2. Target Guided Ordinal Encoding:\n",
        "# Target Guided Ordinal Encoding assigns integers to categories based on their relationship with the target variable.\n",
        "# The categories are ordered by the mean of the target variable for each category.\n",
        "# Example: If you are predicting \"House Price\" (target variable) based on \"Location\" (categorical feature),\n",
        "# you might assign ordinal values to \"Location\" based on the mean price for each location.\n",
        "# This method is useful when there is a relationship between the feature and the target variable.\n",
        "# In a project predicting house prices, you might encode \"Location\" by ranking it according to the average price in each location.\n",
        "\n",
        "# Q3. Covariance:\n",
        "# Covariance is a measure of how two variables change together. It indicates the direction of the linear relationship between variables.\n",
        "# If covariance is positive, the variables tend to increase or decrease together. If negative, one increases while the other decreases.\n",
        "# It is calculated as:\n",
        "# Cov(X, Y) = Î£[(X_i - mean(X)) * (Y_i - mean(Y))] / (n - 1), where n is the number of data points.\n",
        "\n",
        "# Q4. Label Encoding using Python's scikit-learn library:\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define the categorical variables\n",
        "colors = ['red', 'green', 'blue']\n",
        "sizes = ['small', 'medium', 'large']\n",
        "materials = ['wood', 'metal', 'plastic']\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Perform label encoding\n",
        "encoded_colors = label_encoder.fit_transform(colors)\n",
        "encoded_sizes = label_encoder.fit_transform(sizes)\n",
        "encoded_materials = label_encoder.fit_transform(materials)\n",
        "\n",
        "# Output the encoded data\n",
        "encoded_colors, encoded_sizes, encoded_materials\n",
        "\n",
        "# Explanation:\n",
        "# The fit_transform() method converts categorical variables into numeric labels.\n",
        "# For example, encoded_colors might output something like [0, 1, 2], indicating the encoded labels for \"red\", \"green\", and \"blue\".\n",
        "# Similarly, the encoded_sizes and encoded_materials would show their respective label-encoded values.\n",
        "\n",
        "# Q5. Covariance Matrix Calculation:\n",
        "import numpy as np\n",
        "\n",
        "# Dataset of variables (Age, Income, Education Level represented numerically)\n",
        "data = np.array([[25, 30000, 1],  # Age, Income, Education Level (1: High School, 2: Bachelor's, ...)\n",
        "                 [30, 40000, 2],\n",
        "                 [35, 50000, 3],\n",
        "                 [40, 60000, 4]])\n",
        "\n",
        "# Calculate the covariance matrix\n",
        "cov_matrix = np.cov(data, rowvar=False)\n",
        "\n",
        "# Output the covariance matrix\n",
        "cov_matrix\n",
        "\n",
        "# Interpretation:\n",
        "# The covariance matrix shows the covariance between each pair of variables.\n",
        "# For example, cov_matrix[0, 1] represents the covariance between Age and Income.\n",
        "# A positive covariance indicates that as one variable increases, the other tends to increase as well.\n",
        "\n",
        "# Q6. Encoding Methods for Each Variable:\n",
        "\n",
        "# For \"Gender\" (binary categorical):\n",
        "# - One-hot encoding is ideal, as it will create two binary columns (e.g., \"Male\", \"Female\").\n",
        "\n",
        "# For \"Education Level\" (ordinal categorical):\n",
        "# - Ordinal encoding is preferred since the education levels have a natural order (e.g., High School < Bachelor's < Master's < PhD).\n",
        "\n",
        "# For \"Employment Status\" (nominal categorical):\n",
        "# - One-hot encoding is preferred, as the categories do not have an inherent order (e.g., Unemployed, Part-Time, Full-Time).\n",
        "\n",
        "# Q7. Covariance Calculation for Continuous and Categorical Variables:\n",
        "\n",
        "# Let's assume the dataset looks like this (Temperature, Humidity, Weather Condition, Wind Direction):\n",
        "data = np.array([[30, 60, 'Sunny', 'North'],\n",
        "                 [25, 70, 'Cloudy', 'South'],\n",
        "                 [20, 80, 'Rainy', 'East'],\n",
        "                 [35, 50, 'Sunny', 'West']])\n",
        "\n",
        "# For continuous variables (Temperature and Humidity), covariance is calculated between them.\n",
        "# Categorical variables (Weather Condition, Wind Direction) need to be encoded first before calculating covariance.\n",
        "\n",
        "# Example Covariance Calculation:\n",
        "temperature = data[:, 0].astype(float)\n",
        "humidity = data[:, 1].astype(float)\n",
        "\n",
        "# Calculate covariance between Temperature and Humidity\n",
        "cov_temp_humidity = np.cov(temperature, humidity)[0, 1]\n",
        "\n",
        "cov_temp_humidity\n",
        "\n",
        "# Interpretation:\n",
        "# A positive covariance indicates that as temperature increases, humidity also tends to increase.\n",
        "# For categorical variables, we would first apply Label Encoding or One-Hot Encoding before computing covariance.\n"
      ]
    }
  ]
}